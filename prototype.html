<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Zonar Portfolio</title>
    <link rel="icon" href="img/fav.png" type="image/x-icon">

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="ionicons/css/ionicons.min.css" rel="stylesheet">

    <!-- main css -->
    <link href="css/style.css" rel="stylesheet">


    <!-- modernizr -->
    <script src="js/modernizr.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>

    <!-- Preloader -->
    <div id="preloader">
        <div class="pre-container">
            <div class="spinner">
                <div class="double-bounce1"></div>
                <div class="double-bounce2"></div>
            </div>
        </div>
    </div>
    <!-- end Preloader -->

    <div class="container-fluid">
        <!-- box-header -->
        <header class="box-header">
            <div class="box-logo">
                <a href="index.html"><img src="img/logo.png" width="80" alt="Logo"></a>
            </div>
            <!-- box-nav -->
            <a class="box-primary-nav-trigger" href="#0">
                <span class="box-menu-text">Menu</span><span class="box-menu-icon"></span>
            </a>
            <!-- box-primary-nav-trigger -->
        </header>
        <!-- end box-header -->

        <!-- nav -->
      <nav>
            <ul class="box-primary-nav">
                <li class="box-label">2022</li>

                <li><a href="index.html">Intro</a> <i class="ion-ios-circle-filled color"></i></li>
                <li><a href="about.html">About me</a></li>
                <li><a href="creativetech.html">Creative Technology</a></li>  
                <li><a href="duoproj.html">Duo Project</a></li>
                <li><a href="prevproj.html">Previous Projects</a></li>
                <li><a href="personalprojects.html">Personal Projects</a></li>
                <li class="box-label">Follow me</li>
                <li class="box-social"><a href="#0"><i class="ion-social-facebook"></i></a></li>
                <li class="box-social"><a href="#0"><i class="ion-social-instagram-outline"></i></a></li>
                <li class="box-social"><a href="#0"><i class="ion-social-twitter"></i></a></li>
                <li class="box-social"><a href="#0"><i class="ion-social-dribbble"></i></a></li>
            </ul>
        </nav>

        <div class="container main-container">
        
        <div class="col-md-8">
            <h3>Prototype</h3>
            <h4>Neural Home</h4>
            <h5>Our users</h5>
            <p> An everyday task can sometimes be quite difficult for people with severe disabilities.
                 From low mobility to speech impediments. Feeling free and independent is vital to the quality of life.   </p> 
                 <h5>The headset</h5>
                 <p>A Neural Headset is capable of picking up electrical brain activity with seven nodes. Effectively translating 
                     electrical brain intro activity into commands.  These commands are then sent to the Neural Home application with the respectable API.</p>
        <h5>Filtering System</h5>
        <p>The Neural Home application filters the mental and facial commands that it receives from the headset. All of the triggered commands are filtered to 
            ensure the correct user input. </p>
            <h5>Toggle Devices</h5>
            <p>The filtered commands are sent to a Philips Hue HUB and that toggles the desired smart device. Allowing our users to take one step closer
                to full independence. </p>
                    </div>
      
        <div class="col-md-8">
            <iframe width="740" height="406" src="https://www.youtube.com/embed/allGKsfmTBE" title="YouTube video player" frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <p>In this video you can see how the first prototype of the Neural Home. The  smart light bulb on the left is connected to the Neural Home application. On the screen you can 
                see the EmotivBCI displaying the cube. By thinking of the preprogrammed Mental Command, I was able to toggle the connected smart light bulb. 
            </p>
            </div>
            <div class="col-md-8">
                <iframe width="740" height="406" src="https://www.youtube.com/embed/bI3WRzciseQ" title="YouTube video player" frameborder="0" 
                allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            
            <h3>User Interface</h3>
            <h4>Allowing the user control smart devices with facial expressions and mental commands</h4>
           
            <h5>Unlocking the device</h5>
            <p>In the beginning of the video on the right, you can see how the user needs to use a Mental Command to unlock the device.</p>
        
                
                 <h5>Navigating the application</h5>
                As soon as the Mental Command is preformed the user can use their facial expressions to navigate the application. 
                <h5>Face visual</h5>
                The face on the left of thescreen is there to provide feedback for the user, ensuring that the preformed commands are excicuted correctly. 
                When the user preforms a facial expression to go to select the next button, the button get circled until its selected. This visual feedback is there to prevent the user from accidentally 
                selecting a button. The visual feedback is needed, because the user can accidentally trigger the facial expressions without wanting to trigger anything.
            </p>
        </div>
    </div>
    <!-- top-bar -->
    
    <!-- end top-bar -->

    <!-- main-container -->
  
    <!-- end main-container -->


    <!-- footer -->
    <footer>
        <div class="container-fluid">
            <p class="copyright">Zonar Portfolio</p>
        </div>
    </footer>
    <!-- end footer -->

    <!-- back to top -->
    <a href="#0" class="cd-top"><i class="ion-android-arrow-up"></i></a>
    <!-- end back to top -->




    <!-- jQuery -->
    <script src="js/jquery-2.1.1.js"></script>
    <!--  plugins -->
    <script src="js/bootstrap.min.js"></script>
    <script src="js/menu.js"></script>
    <script src="js/animated-headline.js"></script>
    <script src="js/isotope.pkgd.min.js"></script>


    <!--  custom script -->
    <script src="js/custom.js"></script>

    <!-- google analytics  -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-76796224-1', 'auto');
        ga('send', 'pageview');
    </script>

</body>
